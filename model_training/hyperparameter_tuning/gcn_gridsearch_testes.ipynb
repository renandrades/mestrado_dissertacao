{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node classification with Graph Convolutional Network (GCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import mygene\n",
    "import h5py\n",
    "import pickle\n",
    "import argparse\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import stellargraph as sg\n",
    "from stellargraph.layer import GCN\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph import datasets\n",
    "from stellargraph.mapper import (\n",
    "    CorruptedGenerator,\n",
    "    FullBatchNodeGenerator,\n",
    "    GraphSAGENodeGenerator,\n",
    "    HinSAGENodeGenerator,\n",
    "    ClusterNodeGenerator,\n",
    ")\n",
    "\n",
    "from stellargraph.layer import GCN, DeepGraphInfomax, GraphSAGE, GAT, APPNP, HinSAGE\n",
    "from stellargraph.utils import plot_history\n",
    "\n",
    "from tensorflow.keras import layers, optimizers, losses, metrics, Model\n",
    "from sklearn import preprocessing, feature_extraction, model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, ParameterGrid\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import average_precision_score\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import tensorflow as tf\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = pd.read_csv('C:/Users/renan/Desktop/UFRGS/GNN/data/data_final_v2/HPRD_network.tsv', sep='\\t')\n",
    "\n",
    "features = pd.read_csv('C:/Users/renan/Desktop/UFRGS/GNN/data/data_final_v2/HPRD_features_complete.tsv', sep='\\t', index_col='gene')\n",
    "\n",
    "labels = pd.read_csv('C:/Users/renan/Desktop/UFRGS/GNN/data/data_final_v2/HPRD_labels_semisupervised.tsv', sep='\\t', index_col='gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutations 0:48\n",
    "# CNA 16:64\n",
    "# DNA Methylation 0:32 e 16:48\n",
    "# Gene Expression 0:16 e 16:48\n",
    "\n",
    "\n",
    "#features.drop(features.iloc[:, 0:16], inplace = True, axis = 1)\n",
    "#features.drop(features.iloc[:, 16:48], inplace = True, axis = 1)\n",
    "#features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar as labels boleanas em 0/1\n",
    "labels[\"label\"].replace({False: 0, True: 1}, inplace=True)\n",
    "\n",
    "# Transformar as labels vazias em -1\n",
    "labels[\"label\"] = labels.label.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 9438, Edges: 36844\n",
      "\n",
      " Node types:\n",
      "  default: [9438]\n",
      "    Features: float32 vector, length 68\n",
      "    Edge types: default-default->default\n",
      "\n",
      " Edge types:\n",
      "    default-default->default: [36844]\n",
      "        Weights: all 1 (default)\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "G = StellarGraph(edges=network, nodes=features)\n",
    "\n",
    "print(G.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>4873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1.0</th>\n",
       "      <td>3772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label\n",
       " 0.0   4873\n",
       "-1.0   3772\n",
       " 1.0    793"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_classes = labels['label']\n",
    "\n",
    "series_classes.value_counts(dropna = False).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  4532\n",
      "Test:  1134\n",
      "\n",
      "Total:  5666\n"
     ]
    }
   ],
   "source": [
    "# Divisão treino/teste\n",
    "\n",
    "labeled_data = labels[labels['label'] != -1]\n",
    "labeled_data = labeled_data.sample(frac=1)\n",
    "\n",
    "# Um conjunto de teste é utilizado em todos as redes, para isso foi selecionado posteriormente uma lista de genes que é comum à todas as redes\n",
    "test_set = pd.read_csv('C:/Users/renan/Desktop/UFRGS/GNN/data/data_final_v2/test_set_final.tsv', sep='\\t')\n",
    "\n",
    "# Método para separar os dados de treino a partir do test_set\n",
    "# É criada uma nova coluna comparando os genes do banco de teste pré-selecionado com os dados rotulados totais da rede\n",
    "\n",
    "labeled_data['treino'] = labeled_data.index.isin(test_set['gene'])\n",
    "labeled_data.treino.value_counts().to_frame()\n",
    "\n",
    "# Sempre deve existir 1134 True, pois são genes que existem em todas as redes, logo, o restante é separado para treinamento\n",
    "\n",
    "labeled_train_temp = labeled_data[labeled_data['treino'] == False]\n",
    "labeled_test_temp = labeled_data[labeled_data['treino'] == True]\n",
    "\n",
    "labeled_train = labeled_train_temp.drop(columns=['treino'])\n",
    "labeled_test = labeled_test_temp.drop(columns=['treino'])\n",
    "\n",
    "print(\"Train: \", len(labeled_train))\n",
    "print(\"Test: \", len(labeled_test))\n",
    "print(\"\\nTotal: \", len(labeled_train)+len(labeled_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difinição da função de custo Focal Loss\n",
    "\n",
    "import dill\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def binary_focal_loss(gamma=2., alpha=.25):\n",
    "\n",
    "    def binary_focal_loss_fixed(y_true, y_pred):\n",
    "     \n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "        # Define epsilon so that the back-propagation will not result in NaN for 0 divisor case\n",
    "        epsilon = K.epsilon()\n",
    "        # Add the epsilon to prediction value\n",
    "        # y_pred = y_pred + epsilon\n",
    "        # Clip the prediciton value\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
    "        # Calculate p_t\n",
    "        p_t = tf.where(K.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "        # Calculate alpha_t\n",
    "        alpha_factor = K.ones_like(y_true) * alpha\n",
    "        alpha_t = tf.where(K.equal(y_true, 1), alpha_factor, 1 - alpha_factor)\n",
    "        # Calculate cross entropy\n",
    "        cross_entropy = -K.log(p_t)\n",
    "        weight = alpha_t * K.pow((1 - p_t), gamma)\n",
    "        # Calculate focal loss\n",
    "        loss = weight * cross_entropy\n",
    "        # Sum the losses in mini_batch\n",
    "        loss = K.mean(K.sum(loss, axis=1))\n",
    "        return loss\n",
    "\n",
    "    return binary_focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GCN (local pooling) filters...\n"
     ]
    }
   ],
   "source": [
    "target_encoding = preprocessing.LabelBinarizer()\n",
    "\n",
    "train_targets = target_encoding.fit_transform(labeled_train)\n",
    "test_targets = target_encoding.transform(labeled_test)\n",
    "\n",
    "\n",
    "\n",
    "generator = FullBatchNodeGenerator(G, method=\"gcn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "\n",
    "params = {'layer_sizes':[[64, 64], [128, 128], [256, 256]],\n",
    "        'activations': [[\"ReLU\", \"ReLU\"], [\"PReLU\", \"PReLU\"]],\n",
    "        'dropout':[0.001, 0.01, 0.1],\n",
    "        'learning_rate':[0.00001, 0.0001, 0.001],\n",
    "        'epochs':[500],\n",
    "        'gamma':[0, 0.5, 1, 2],\n",
    "        'alpha':[0.25, 0.50, 0.75, 0.90]\n",
    "        }\n",
    "\n",
    "\n",
    "num_of_settings = len(list(ParameterGrid(params)))\n",
    "print (\"Grid Search: Trying {} different parameter settings...\".format(num_of_settings))\n",
    "param_num = 0\n",
    "\n",
    "for param_set in list(ParameterGrid(params)):\n",
    "\n",
    "  num_folds = 5\n",
    "\n",
    "  auc_pr_per_fold = []\n",
    "  loss_per_fold = []\n",
    "\n",
    "  kfold = StratifiedKFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "  fold_no = 1\n",
    "  for train, test in kfold.split(labeled_train.index, train_targets):\n",
    "\n",
    "    train_gen = generator.flow(labeled_train.index[train], train_targets[train])\n",
    "\n",
    "    gcn = GCN(\n",
    "      layer_sizes=param_set['layer_sizes'], activations=param_set['activations'], generator=generator, dropout=param_set['dropout']\n",
    "    )\n",
    "\n",
    "    x_inp, x_out = gcn.in_out_tensors()\n",
    "\n",
    "    predictions = layers.Dense(units=train_targets.shape[1], activation=\"sigmoid\")(x_out)\n",
    "\n",
    "    model = Model(inputs=x_inp, outputs=predictions)\n",
    "    model.compile(\n",
    "      optimizer=optimizers.Adam(learning_rate=param_set['learning_rate']),\n",
    "      #loss=losses.binary_crossentropy,\n",
    "      loss=[binary_focal_loss(gamma=param_set['gamma'], alpha=param_set['alpha'])],\n",
    "      metrics=[\"acc\", metrics.AUC(curve=\"ROC\", name=\"auc_roc\"), metrics.AUC(curve=\"PR\", name=\"auc_pr\")],\n",
    "    )\n",
    "\n",
    "    val_gen = generator.flow(labeled_train.index[test], train_targets[test])\n",
    "\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    history = model.fit(\n",
    "      train_gen,\n",
    "      epochs=param_set['epochs'],\n",
    "      validation_data=val_gen,\n",
    "      verbose=2,\n",
    "      shuffle=False,\n",
    "    )\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    #val_gen = generator.flow(labeled_train.index[test], train_targets[test])\n",
    "    scores = model.evaluate(val_gen, verbose=0)\n",
    "    print('\\n')\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[3]} of {scores[3]*100}%')\n",
    "    auc_pr_per_fold.append(scores[3] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Save history to csv\n",
    "    hist_df = pd.DataFrame(history.history)\n",
    "    hist_csv_file = f'hprd_paramset{param_num}_fold{fold_no}.csv'\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "      hist_df.to_csv(f)  \n",
    "    f.close()\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "  # Provide average scores\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print('Score per fold')\n",
    "  for i in range(0, len(auc_pr_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - AUC PR: {auc_pr_per_fold[i]}%')\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print('Average scores for all folds:')\n",
    "  print(f'> AUC PR: {np.mean(auc_pr_per_fold)} (+- {np.std(auc_pr_per_fold)})')\n",
    "  print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "  print('------------------------------------------------------------------------')\n",
    "\n",
    "  param_num += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search: Trying 864 different parameter settings...\n",
      "[113 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[114 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[115 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[116 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[117 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[118 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[119 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[120 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[121 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[122 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[123 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[124 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[125 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[126 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[127 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[128 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[129 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[130 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[131 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[132 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[133 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[134 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[135 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[136 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[137 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[138 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[139 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[140 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[141 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[142 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[143 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[144 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[145 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[146 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[147 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[148 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[149 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[150 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[151 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[152 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[153 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[154 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[155 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[156 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[157 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[158 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[159 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[160 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[161 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[162 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[163 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[164 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[165 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[166 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[167 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[168 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[169 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[170 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[171 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[172 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[173 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[174 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[175 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[176 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[177 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[178 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[179 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[180 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[181 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[182 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[183 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[184 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[185 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[186 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[187 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[188 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[189 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[190 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[191 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[192 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[193 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[194 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[195 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[196 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[197 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[198 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[199 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[200 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[201 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[202 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[203 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[204 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[205 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[206 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[207 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[208 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[209 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[210 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[211 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[212 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[213 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[214 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[215 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[216 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[217 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[218 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[219 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[220 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[221 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[222 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[223 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[224 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[225 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[226 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[227 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[228 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[229 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[230 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[231 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[232 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[233 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[234 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[235 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[236 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[237 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[238 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[239 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[240 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[241 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[242 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[243 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[244 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[245 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[246 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[247 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[248 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[249 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[250 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[251 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[252 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[253 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[254 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[255 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[256 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[257 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[258 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[259 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[260 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[261 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[262 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[263 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[264 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[265 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[266 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[267 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[268 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[269 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[270 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[271 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[272 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[273 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[274 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[275 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[276 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[277 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[278 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[279 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[280 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[281 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[282 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[283 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[284 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[285 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[286 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[287 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[288 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[289 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[290 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[291 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[292 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[293 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[294 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[295 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[296 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[297 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[298 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[299 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[300 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[301 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[302 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[303 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[304 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[305 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[306 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[307 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[308 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[309 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[310 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[311 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[312 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[313 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[314 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[315 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[316 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[317 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[318 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[319 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[320 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[321 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[322 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[323 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[324 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[325 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[326 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[327 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[328 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[329 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[330 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[331 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[332 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[333 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[334 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[335 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[336 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[337 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[338 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[339 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[340 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[341 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[342 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[343 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[344 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[345 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[346 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[347 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[348 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[349 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[350 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[351 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[352 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[353 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[354 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[355 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[356 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[357 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[358 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[359 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[360 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[361 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[362 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[363 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[364 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[365 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[366 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[367 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[368 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[369 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[370 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[371 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[372 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[373 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[374 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[375 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[376 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[377 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[378 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[379 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[380 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[381 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[382 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[383 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[384 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[385 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[386 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[387 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[388 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[389 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[390 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[391 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[392 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[393 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[394 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[395 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[396 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[397 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[398 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[399 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[400 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[401 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[402 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[403 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[404 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[405 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[406 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[407 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[408 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[409 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[410 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[411 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[412 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[413 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[414 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[415 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[416 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[417 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[418 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[419 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[420 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[421 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[422 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[423 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[424 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[425 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[426 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[427 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[428 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[429 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[430 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[431 out of 864 combinations]: {'activations': ['ReLU', 'ReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[432 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[433 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[434 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[435 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[436 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[437 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[438 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[439 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[440 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[441 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[442 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[443 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[444 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[445 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[446 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[447 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[448 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[449 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[450 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[451 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[452 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[453 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[454 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[455 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[456 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[457 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[458 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[459 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[460 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[461 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[462 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[463 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[464 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[465 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[466 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[467 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[468 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[469 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[470 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[471 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[472 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[473 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[474 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[475 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[476 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[477 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[478 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[479 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[480 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[481 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[482 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[483 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[484 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[485 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[486 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[487 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[488 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[489 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[490 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[491 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[492 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[493 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[494 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[495 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[496 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[497 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[498 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[499 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[500 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[501 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[502 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[503 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[504 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[505 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[506 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[507 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[508 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[509 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[510 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[511 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[512 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[513 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[514 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[515 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[516 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[517 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[518 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[519 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[520 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[521 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[522 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[523 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[524 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[525 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[526 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[527 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[528 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[529 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[530 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[531 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[532 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[533 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[534 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[535 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[536 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[537 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[538 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[539 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[540 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[541 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[542 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[543 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[544 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[545 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[546 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[547 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[548 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[549 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[550 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[551 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[552 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[553 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[554 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[555 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[556 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[557 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[558 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[559 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[560 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[561 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[562 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[563 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[564 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[565 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[566 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[567 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[568 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[569 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[570 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[571 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[572 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[573 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[574 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[575 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[576 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[577 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[578 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[579 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[580 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[581 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[582 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[583 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[584 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[585 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[586 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[587 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[588 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[589 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[590 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[591 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[592 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[593 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[594 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[595 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[596 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[597 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[598 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[599 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[600 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[601 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[602 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[603 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[604 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[605 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[606 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[607 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[608 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[609 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[610 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[611 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[612 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[613 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[614 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[615 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[616 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[617 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[618 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[619 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[620 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[621 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[622 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[623 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[624 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[625 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[626 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[627 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[628 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[629 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[630 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[631 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[632 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[633 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[634 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[635 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[636 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[637 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[638 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[639 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[640 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[641 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[642 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[643 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[644 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[645 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[646 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[647 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[648 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[649 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[650 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[651 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[652 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[653 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[654 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[655 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[656 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[657 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[658 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[659 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[660 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[661 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[662 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[663 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[664 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[665 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[666 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[667 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[668 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[669 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[670 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[671 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[672 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[673 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[674 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[675 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[676 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[677 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[678 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[679 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[680 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[681 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[682 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[683 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[684 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[685 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[686 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[687 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[688 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[689 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[690 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[691 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[692 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[693 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[694 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[695 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[696 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[697 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[698 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[699 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[700 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[701 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[702 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[703 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[704 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[705 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[706 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[707 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[708 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[709 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[710 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[711 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[712 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[713 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[714 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[715 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[716 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[717 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[718 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[719 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[720 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[721 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[722 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[723 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[724 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[725 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[726 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[727 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[728 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[729 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[730 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[731 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[732 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[733 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[734 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[735 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[736 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[737 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[738 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[739 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[740 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[741 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[742 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[743 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[744 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[745 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[746 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[747 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[748 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[749 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[750 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[751 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[752 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[753 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[754 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[755 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[756 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[757 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[758 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[759 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[760 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[761 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[762 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[763 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[764 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[765 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[766 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[767 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[768 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[769 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[770 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[771 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[772 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[773 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[774 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[775 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[776 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[777 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[778 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[779 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[780 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[781 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[782 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[783 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[784 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[785 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[786 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[787 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[788 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[789 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[790 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[791 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[792 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[793 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[794 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[795 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[796 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[797 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[798 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[799 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[800 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[801 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[802 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[803 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[804 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[805 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[806 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[807 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[808 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[809 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[810 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[811 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[812 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[813 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[814 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[815 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[816 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[817 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[818 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[819 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[820 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[821 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[822 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[823 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[824 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[825 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[826 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[827 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[828 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[829 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[830 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[831 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[832 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[833 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[834 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[835 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[836 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[837 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[838 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[839 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[840 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[841 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[842 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[843 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[844 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[845 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[846 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[847 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[848 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[849 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[850 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[851 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[852 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[853 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[854 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[855 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 1e-05}\n",
      "[856 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.0001}\n",
      "[857 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[858 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 1e-05}\n",
      "[859 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.0001}\n",
      "[860 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[861 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 1e-05}\n",
      "[862 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.0001}\n",
      "[863 out of 864 combinations]: {'activations': ['PReLU', 'PReLU'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "\n",
    "params = {'layer_sizes':[[64, 64], [128, 128], [256, 256]],\n",
    "        'activations': [[\"ReLU\", \"ReLU\"], [\"PReLU\", \"PReLU\"]],\n",
    "        'dropout':[0.001, 0.01, 0.1],\n",
    "        'learning_rate':[0.00001, 0.0001, 0.001],\n",
    "        'epochs':[500],\n",
    "        'gamma':[0, 0.5, 1, 2],\n",
    "        'alpha':[0.25, 0.50, 0.75, 0.90]\n",
    "        }\n",
    "\n",
    "\n",
    "num_of_settings = len(list(ParameterGrid(params)))\n",
    "print (\"Grid Search: Trying {} different parameter settings...\".format(num_of_settings))\n",
    "param_num = 0\n",
    "\n",
    "for param_set in list(ParameterGrid(params)):\n",
    "        if param_num < 113:\n",
    "                param_num+=1\n",
    "        else:\n",
    "                print (\"[{} out of {} combinations]: {}\".format(param_num, num_of_settings, param_set))\n",
    "                param_num += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search: Trying 288 different parameter settings...\n",
      "[0 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[1 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[2 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[3 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[4 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[5 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[6 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[7 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[8 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[9 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[10 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[11 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[12 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[13 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[14 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[15 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[16 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[17 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[18 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[19 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[20 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[21 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[22 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[23 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[24 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[25 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[26 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[27 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[28 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[29 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[30 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[31 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[32 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[33 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[34 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[35 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[36 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[37 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[38 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[39 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[40 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[41 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[42 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[43 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[44 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[45 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[46 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[47 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[48 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[49 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[50 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[51 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[52 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[53 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[54 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[55 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[56 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[57 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[58 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[59 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[60 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[61 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[62 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[63 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[64 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[65 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[66 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[67 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[68 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[69 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[70 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[71 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.25, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[72 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[73 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[74 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[75 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[76 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[77 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[78 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[79 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[80 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[81 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[82 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[83 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[84 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[85 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[86 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[87 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[88 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[89 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[90 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[91 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[92 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[93 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[94 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[95 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[96 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[97 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[98 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[99 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[100 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[101 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[102 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[103 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[104 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[105 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[106 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[107 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[108 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[109 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[110 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[111 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[112 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[113 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[114 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[115 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[116 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[117 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[118 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[119 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[120 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[121 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[122 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[123 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[124 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[125 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[126 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[127 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[128 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[129 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[130 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[131 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[132 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[133 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[134 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[135 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[136 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[137 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[138 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[139 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[140 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[141 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[142 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[143 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.5, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[144 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[145 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[146 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[147 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[148 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[149 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[150 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[151 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[152 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[153 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[154 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[155 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[156 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[157 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[158 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[159 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[160 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[161 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[162 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[163 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[164 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[165 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[166 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[167 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[168 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[169 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[170 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[171 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[172 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[173 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[174 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[175 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[176 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[177 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[178 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[179 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[180 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[181 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[182 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[183 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[184 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[185 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[186 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[187 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[188 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[189 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[190 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[191 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[192 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[193 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[194 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[195 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[196 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[197 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[198 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[199 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[200 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[201 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[202 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[203 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[204 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[205 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[206 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[207 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[208 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[209 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[210 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[211 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[212 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[213 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[214 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[215 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.75, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[216 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[217 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[218 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[219 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[220 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[221 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[222 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[223 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[224 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[225 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[226 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[227 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[228 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[229 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[230 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[231 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[232 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[233 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[234 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[235 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[236 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[237 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[238 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[239 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.001, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[240 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[241 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[242 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[243 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[244 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[245 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[246 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[247 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[248 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[249 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[250 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[251 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[252 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[253 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[254 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[255 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[256 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[257 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[258 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[259 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[260 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[261 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[262 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[263 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.01, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[264 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[265 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[266 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[267 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[268 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[269 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[270 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[271 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[272 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[273 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[274 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[275 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 0.5, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[276 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[277 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[278 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[279 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[280 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[281 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 1, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n",
      "[282 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.001}\n",
      "[283 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [64, 64], 'learning_rate': 0.005}\n",
      "[284 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.001}\n",
      "[285 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [128, 128], 'learning_rate': 0.005}\n",
      "[286 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.001}\n",
      "[287 out of 288 combinations]: {'activations': ['relu', 'relu'], 'alpha': 0.9, 'dropout': 0.1, 'epochs': 500, 'gamma': 2, 'layer_sizes': [256, 256], 'learning_rate': 0.005}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "\n",
    "params = {'layer_sizes':[[64, 64], [128, 128], [256, 256]],\n",
    "        'activations': [[\"relu\", \"relu\"]],\n",
    "        'dropout':[0.001, 0.01, 0.1],\n",
    "        'learning_rate':[0.001, 0.005],\n",
    "        'epochs':[500],\n",
    "        'gamma':[0, 0.5, 1, 2],\n",
    "        'alpha':[0.25, 0.50, 0.75, 0.90]\n",
    "        }\n",
    "\n",
    "\n",
    "num_of_settings = len(list(ParameterGrid(params)))\n",
    "print (\"Grid Search: Trying {} different parameter settings...\".format(num_of_settings))\n",
    "param_num = 0\n",
    "\n",
    "for param_set in list(ParameterGrid(params)):\n",
    "    print (\"[{} out of {} combinations]: {}\".format(param_num, num_of_settings, param_set))\n",
    "    train_probs = pd.DataFrame({\"paramset\": param_num, \"param\": param_set})\n",
    "    param_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.25,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.5,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.75,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.001,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.01,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 0.5,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 1,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [64, 64],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [128, 128],\n",
       "  'learning_rate': 0.005},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.001},\n",
       " {'activations': ['relu', 'relu'],\n",
       "  'alpha': 0.9,\n",
       "  'dropout': 0.1,\n",
       "  'epochs': 500,\n",
       "  'gamma': 2,\n",
       "  'layer_sizes': [256, 256],\n",
       "  'learning_rate': 0.005}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_parametros = list(ParameterGrid(params))\n",
    "lista_parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activations</th>\n",
       "      <th>alpha</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>gamma</th>\n",
       "      <th>layer_sizes</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[relu, relu]</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[64, 64]</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[relu, relu]</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[64, 64]</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[relu, relu]</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[128, 128]</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[relu, relu]</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[128, 128]</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[relu, relu]</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[256, 256]</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>[relu, relu]</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.100</td>\n",
       "      <td>500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[64, 64]</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>[relu, relu]</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.100</td>\n",
       "      <td>500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[128, 128]</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>[relu, relu]</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.100</td>\n",
       "      <td>500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[128, 128]</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>[relu, relu]</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.100</td>\n",
       "      <td>500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[256, 256]</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>[relu, relu]</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.100</td>\n",
       "      <td>500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[256, 256]</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      activations  alpha  dropout  epochs  gamma layer_sizes  learning_rate\n",
       "0    [relu, relu]   0.25    0.001     500    0.0    [64, 64]          0.001\n",
       "1    [relu, relu]   0.25    0.001     500    0.0    [64, 64]          0.005\n",
       "2    [relu, relu]   0.25    0.001     500    0.0  [128, 128]          0.001\n",
       "3    [relu, relu]   0.25    0.001     500    0.0  [128, 128]          0.005\n",
       "4    [relu, relu]   0.25    0.001     500    0.0  [256, 256]          0.001\n",
       "..            ...    ...      ...     ...    ...         ...            ...\n",
       "283  [relu, relu]   0.90    0.100     500    2.0    [64, 64]          0.005\n",
       "284  [relu, relu]   0.90    0.100     500    2.0  [128, 128]          0.001\n",
       "285  [relu, relu]   0.90    0.100     500    2.0  [128, 128]          0.005\n",
       "286  [relu, relu]   0.90    0.100     500    2.0  [256, 256]          0.001\n",
       "287  [relu, relu]   0.90    0.100     500    2.0  [256, 256]          0.005\n",
       "\n",
       "[288 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame (lista_parametros, columns = ['activations', 'alpha', 'dropout', 'epochs', 'gamma', 'layer_sizes', 'learning_rate'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activations</th>\n",
       "      <th>alpha</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>gamma</th>\n",
       "      <th>layer_sizes</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>paramset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[relu, relu]</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[64, 64]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[relu, relu]</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[64, 64]</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[relu, relu]</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[128, 128]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[relu, relu]</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[128, 128]</td>\n",
       "      <td>0.005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[relu, relu]</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[256, 256]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>[relu, relu]</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.100</td>\n",
       "      <td>500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[64, 64]</td>\n",
       "      <td>0.005</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>[relu, relu]</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.100</td>\n",
       "      <td>500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[128, 128]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>[relu, relu]</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.100</td>\n",
       "      <td>500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[128, 128]</td>\n",
       "      <td>0.005</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>[relu, relu]</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.100</td>\n",
       "      <td>500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[256, 256]</td>\n",
       "      <td>0.001</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>[relu, relu]</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.100</td>\n",
       "      <td>500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[256, 256]</td>\n",
       "      <td>0.005</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      activations  alpha  dropout  epochs  gamma layer_sizes  learning_rate  \\\n",
       "0    [relu, relu]   0.25    0.001     500    0.0    [64, 64]          0.001   \n",
       "1    [relu, relu]   0.25    0.001     500    0.0    [64, 64]          0.005   \n",
       "2    [relu, relu]   0.25    0.001     500    0.0  [128, 128]          0.001   \n",
       "3    [relu, relu]   0.25    0.001     500    0.0  [128, 128]          0.005   \n",
       "4    [relu, relu]   0.25    0.001     500    0.0  [256, 256]          0.001   \n",
       "..            ...    ...      ...     ...    ...         ...            ...   \n",
       "283  [relu, relu]   0.90    0.100     500    2.0    [64, 64]          0.005   \n",
       "284  [relu, relu]   0.90    0.100     500    2.0  [128, 128]          0.001   \n",
       "285  [relu, relu]   0.90    0.100     500    2.0  [128, 128]          0.005   \n",
       "286  [relu, relu]   0.90    0.100     500    2.0  [256, 256]          0.001   \n",
       "287  [relu, relu]   0.90    0.100     500    2.0  [256, 256]          0.005   \n",
       "\n",
       "     paramset  \n",
       "0           0  \n",
       "1           1  \n",
       "2           2  \n",
       "3           3  \n",
       "4           4  \n",
       "..        ...  \n",
       "283       283  \n",
       "284       284  \n",
       "285       285  \n",
       "286       286  \n",
       "287       287  \n",
       "\n",
       "[288 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['paramset'] = np.arange(len(df))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(f'C:/Users/renan/Desktop/experiments/GCN/gridsearch/paramset2.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-8d0b4c623a49>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'params.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'cap' is not defined"
     ]
    }
   ],
   "source": [
    "%%capture cap --no-stderr\n",
    "\n",
    "param_num = 0\n",
    "for param_set in list(ParameterGrid(params)):\n",
    "    print (\"[{} out of {} combinations]: {}\".format(param_num, num_of_settings, param_set))\n",
    "    param_num += 1\n",
    "\n",
    "\n",
    "with open('params.txt', 'w') as f:\n",
    "    f.write(str(cap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 237ms/step - loss: 0.2463 - acc: 0.9123 - auc_roc: 0.8162 - auc_pr: 0.4019\n",
      "\n",
      "Test Set Metrics:\n",
      "\tloss: 0.2463\n",
      "\tacc: 0.9123\n",
      "\tauc_roc: 0.8162\n",
      "\tauc_pr: 0.4019\n"
     ]
    }
   ],
   "source": [
    "# Execução para os dados de teste\n",
    "\n",
    "test_gen = generator.flow(labeled_test.index, test_targets)\n",
    "test_metrics = model.evaluate(test_gen)\n",
    "\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "for name, val in zip(model.metrics_names, test_metrics):\n",
    "    print(\"\\t{}: {:0.4f}\".format(name, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando um dataframe com as probabilidades na etapa de teste\n",
    "\n",
    "nodes_test = labeled_test.index\n",
    "gen_test = generator.flow(nodes_test)\n",
    "test_predictions = model.predict(gen_test)\n",
    "\n",
    "test_predictions2 = target_encoding.inverse_transform(test_predictions.squeeze())\n",
    "\n",
    "train_probs = pd.DataFrame({\"Predicted\": test_predictions2, \"Probability\": test_predictions.squeeze(), \"True\": labeled_test['label']})\n",
    "\n",
    "# Save to csv\n",
    "pred_test_csv_file = f'test_predictions_hprd_6a.csv'\n",
    "with open(pred_test_csv_file, mode='w') as f:\n",
    "    train_probs.to_csv(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes = series_classes.index\n",
    "all_gen = generator.flow(all_nodes)\n",
    "all_predictions = model.predict(all_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.0    8486\n",
      "-1.0    4633\n",
      " 1.0     868\n",
      "Name: True, dtype: int64 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0    13597\n",
       "1.0      390\n",
       "Name: Predicted, dtype: int64"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_predictions = target_encoding.inverse_transform(all_predictions.squeeze())\n",
    "df = pd.DataFrame({\"Predicted\": node_predictions, \"True\": series_classes})\n",
    "\n",
    "#df.head(20)\n",
    "\n",
    "print(df['True'].value_counts(), \"\\n\")\n",
    "df['Predicted'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar a variável all_predictions e a node_predictions para comparar\n",
    "# Usar a all_predictions para gerar gráficos da fig3 do artigo, sobre distribuição de nós \n",
    "\n",
    "df_predictions = pd.DataFrame({\"percent\": all_predictions.squeeze(), \"binary\": node_predictions, \"true\": series_classes})\n",
    "\n",
    "# Save to csv\n",
    "pred_csv_file = f'all_predictions_hprd_6a.csv'\n",
    "with open(pred_csv_file, mode='w') as f:\n",
    "    df_predictions.to_csv(f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "89ca77ca0a9586cfd31e6489ec801d820c8da6030c191f37a447e04204fb076d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
