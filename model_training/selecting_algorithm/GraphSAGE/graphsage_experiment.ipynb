{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node classification with GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mygene\n",
    "import h5py\n",
    "import pickle\n",
    "import argparse\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "import stellargraph as sg\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph import datasets\n",
    "from stellargraph.mapper import (\n",
    "    CorruptedGenerator,\n",
    "    FullBatchNodeGenerator,\n",
    "    GraphSAGENodeGenerator,\n",
    "    HinSAGENodeGenerator,\n",
    "    ClusterNodeGenerator,\n",
    ")\n",
    "\n",
    "from stellargraph.layer import GCN, DeepGraphInfomax, GraphSAGE, GAT, APPNP, HinSAGE\n",
    "from stellargraph.utils import plot_history\n",
    "\n",
    "from tensorflow.keras import layers, optimizers, losses, metrics, Model\n",
    "from sklearn import preprocessing, feature_extraction, model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, ParameterGrid\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import average_precision_score\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import tensorflow as tf\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "DataLoading"
    ]
   },
   "outputs": [],
   "source": [
    "network = pd.read_csv('C:/Users/renan/Desktop/UFRGS/GNN/data/data_final_v2/HPRD_network.tsv', sep='\\t')\n",
    "\n",
    "features = pd.read_csv('C:/Users/renan/Desktop/UFRGS/GNN/data/data_final_v2/HPRD_features_complete.tsv', sep='\\t', index_col='gene')\n",
    "\n",
    "labels = pd.read_csv('C:/Users/renan/Desktop/UFRGS/GNN/data/data_final_v2/HPRD_labels_semisupervised.tsv', sep='\\t', index_col='gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutations 0:48\n",
    "# CNA 16:64\n",
    "# DNA Methylation 0:32 e 16:48\n",
    "# Gene Expression 0:16 e 16:48\n",
    "\n",
    "#features.drop(features.iloc[:, 0:16], inplace = True, axis = 1)\n",
    "#features.drop(features.iloc[:, 16:48], inplace = True, axis = 1)\n",
    "#features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar as labels boleanas em 0/1\n",
    "labels[\"label\"].replace({False: 0, True: 1}, inplace=True)\n",
    "\n",
    "# Transformar as labels vazias em -1\n",
    "labels[\"label\"] = labels.label.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 9438, Edges: 36844\n",
      "\n",
      " Node types:\n",
      "  default: [9438]\n",
      "    Features: float32 vector, length 68\n",
      "    Edge types: default-default->default\n",
      "\n",
      " Edge types:\n",
      "    default-default->default: [36844]\n",
      "        Weights: all 1 (default)\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "G = StellarGraph(edges=network, nodes=features)\n",
    "\n",
    "print(G.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>4873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1.0</th>\n",
       "      <td>3772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label\n",
       " 0.0   4873\n",
       "-1.0   3772\n",
       " 1.0    793"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_classes = labels['label']\n",
    "\n",
    "series_classes.value_counts(dropna = False).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  4532\n",
      "Test:  1134\n",
      "\n",
      "Total:  5666\n"
     ]
    }
   ],
   "source": [
    "# Dividir os dados em treino e teste apenas, usando a proporção 80/20\n",
    "\n",
    "train_ratio = 0.80\n",
    "test_ratio = 0.20\n",
    "\n",
    "labeled_data = labels[labels['label'] != -1]\n",
    "labeled_data = labeled_data.sample(frac=1)\n",
    "\n",
    "# Aqui aplica-se então 20% do tamanho total da rede e o restante para treino\n",
    "labeled_train, labeled_test = model_selection.train_test_split(\n",
    "    labeled_data, test_size=test_ratio, stratify=labeled_data)\n",
    "\n",
    "\n",
    "print(\"Train: \", len(labeled_train))\n",
    "print(\"Test: \", len(labeled_test))\n",
    "print(\"\\nTotal: \", len(labeled_train)+len(labeled_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difinição da função de custo Focal Loss\n",
    "\n",
    "import dill\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def binary_focal_loss(gamma=2., alpha=.25):\n",
    "\n",
    "    def binary_focal_loss_fixed(y_true, y_pred):\n",
    "     \n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "        # Define epsilon so that the back-propagation will not result in NaN for 0 divisor case\n",
    "        epsilon = K.epsilon()\n",
    "        # Add the epsilon to prediction value\n",
    "        # y_pred = y_pred + epsilon\n",
    "        # Clip the prediciton value\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
    "        # Calculate p_t\n",
    "        p_t = tf.where(K.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "        # Calculate alpha_t\n",
    "        alpha_factor = K.ones_like(y_true) * alpha\n",
    "        alpha_t = tf.where(K.equal(y_true, 1), alpha_factor, 1 - alpha_factor)\n",
    "        # Calculate cross entropy\n",
    "        cross_entropy = -K.log(p_t)\n",
    "        weight = alpha_t * K.pow((1 - p_t), gamma)\n",
    "        # Calculate focal loss\n",
    "        loss = weight * cross_entropy\n",
    "        # Sum the losses in mini_batch\n",
    "        loss = K.mean(K.sum(loss, axis=1))\n",
    "        return loss\n",
    "\n",
    "    return binary_focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encoding = preprocessing.LabelBinarizer()\n",
    "\n",
    "train_targets = target_encoding.fit_transform(labeled_train)\n",
    "test_targets = target_encoding.transform(labeled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "num_samples = [10, 5]\n",
    "\n",
    "generator = GraphSAGENodeGenerator(G, batch_size, num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "num_folds = 5\n",
    "\n",
    "auc_pr_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(labeled_train.index, train_targets):\n",
    "\n",
    "  train_gen = generator.flow(labeled_train.index[train], train_targets[train], shuffle=True)\n",
    "\n",
    "  graphsage_model = GraphSAGE(\n",
    "    layer_sizes=[64, 64], generator=generator, bias=True, dropout=0.01,\n",
    "  )\n",
    "\n",
    "  x_inp, x_out = graphsage_model.in_out_tensors()\n",
    "  prediction = layers.Dense(units=train_targets.shape[1], activation=\"sigmoid\")(x_out)\n",
    "\n",
    "  model = Model(inputs=x_inp, outputs=prediction)\n",
    "  model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "    loss=losses.binary_crossentropy,\n",
    "    #loss=[binary_focal_loss(gamma=0.5, alpha=0.50)],\n",
    "    metrics=[\"acc\", metrics.AUC(curve=\"ROC\", name=\"auc_roc\"), metrics.AUC(curve=\"PR\", name=\"auc_pr\")],\n",
    "  )\n",
    "\n",
    "  val_gen = generator.flow(labeled_train.index[test], train_targets[test])\n",
    "\n",
    "\n",
    "  # Generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  history = model.fit(\n",
    "    train_gen, epochs=300, validation_data=val_gen, verbose=2, shuffle=False\n",
    "  )\n",
    "\n",
    "  # Generate generalization metrics\n",
    "  #val_gen = generator.flow(labeled_train.index[test], train_targets[test])\n",
    "  scores = model.evaluate(val_gen, verbose=0)\n",
    "  print('\\n')\n",
    "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[3]} of {scores[3]*100}%')\n",
    "  auc_pr_per_fold.append(scores[3] * 100)\n",
    "  loss_per_fold.append(scores[0])\n",
    "\n",
    "  # Save history to csv\n",
    "  hist_df = pd.DataFrame(history.history)\n",
    "\n",
    "  hist_csv_file = f'fold{fold_no}_hprd_6a.csv'\n",
    "  with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)\n",
    "  f.close()\n",
    "\n",
    "  # Increase fold number\n",
    "  fold_no = fold_no + 1\n",
    "\n",
    "# Provide average scores\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(auc_pr_per_fold)):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - AUC PR: {auc_pr_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> AUC PR: {np.mean(auc_pr_per_fold)} (+- {np.std(auc_pr_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execução para os dados de teste\n",
    "\n",
    "test_gen = generator.flow(labeled_test.index, test_targets)\n",
    "test_metrics = model.evaluate(test_gen)\n",
    "\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "for name, val in zip(model.metrics_names, test_metrics):\n",
    "    print(\"\\t{}: {:0.4f}\".format(name, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes = series_classes.index\n",
    "all_mapper = generator.flow(all_nodes)\n",
    "all_predictions = model.predict(all_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_predictions = target_encoding.inverse_transform(all_predictions)\n",
    "df = pd.DataFrame({\"Predicted\": node_predictions, \"True\": series_classes})\n",
    "\n",
    "#df.head(10)\n",
    "\n",
    "print(df['True'].value_counts(), \"\\n\")\n",
    "df['Predicted'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "89ca77ca0a9586cfd31e6489ec801d820c8da6030c191f37a447e04204fb076d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
